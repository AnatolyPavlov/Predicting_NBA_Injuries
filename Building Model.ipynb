{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as scs\n",
    "import re\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import auc, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from collections import defaultdict\n",
    "import cPickle as pickle\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to extract information from the json files\n",
    "def json_extract(file):\n",
    "    with open('data/{}'.format(file)) as f:\n",
    "        data = json.load(f)\n",
    "        cols = data['resultSets'][0]['headers']\n",
    "        vals = data['resultSets'][0]['rowSet']\n",
    "    return cols, vals\n",
    "\n",
    "\n",
    "# function to create dataframe from the json information\n",
    "# keyword = gamelog, season_stats, or heights_weights\n",
    "def create_df(keyword, add_year=False):\n",
    "\n",
    "    fns = os.listdir('data/')\n",
    "\n",
    "    cols = json_extract('2013_{}.json'.format(keyword))[0]\n",
    "    if add_year:\n",
    "        cols += ['YEAR']\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for fn in fns:\n",
    "        if keyword in fn:\n",
    "            tmp_cols, tmp_vals = json_extract(fn)\n",
    "            df_tmp = pd.DataFrame(tmp_vals, columns=tmp_cols)\n",
    "            if add_year:\n",
    "                df_tmp['YEAR'] = int(fn[0:4])\n",
    "            df = df.append(df_tmp)\n",
    "            del df_tmp, tmp_cols, tmp_vals\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_date(df, date_col, create_sep_cols=True):\n",
    "\n",
    "    df[date_col] = pd.to_datetime(df[date_col], infer_datetime_format=True)\n",
    "    if create_sep_cols:\n",
    "        date = df[date_col]\n",
    "        df['YEAR'] = date.apply(lambda x: x.year)\n",
    "        df['MONTH'] = date.apply(lambda x: x.month)\n",
    "        df['DAY'] = date.apply(lambda x: x.day)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_notes(x):\n",
    "    found = re.findall(r'\\s\\(\\w\\)', x)\n",
    "    if found:\n",
    "        return x.replace(found[0], '')\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    \n",
    "# preprocess injury df\n",
    "def prep_injury(df):\n",
    "\n",
    "    drop_vars = ['Unnamed: 0', 'Team']\n",
    "    df.drop(drop_vars, axis=1, inplace=True)\n",
    "    \n",
    "    # converting the Date column to datetime objects\n",
    "    df = parse_date(df, 'Date')\n",
    "#     df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # filter out all events not directly related to basketball\n",
    "    df = df[(~df['Notes'].str.contains('flu')) &\n",
    "            (~df['Notes'].str.contains('rest')) &\n",
    "            (~df['Notes'].str.contains('jail')) &\n",
    "            (~df['Notes'].str.contains('ill')) &\n",
    "            (~df['Notes'].str.contains('asthma')) &\n",
    "            (~df['Notes'].str.contains('virus')) &\n",
    "            (~df['Notes'].str.contains('return')) &\n",
    "            (~df['Notes'].str.contains('pneumonia')) &\n",
    "            (~df['Notes'].str.contains('coach')) &\n",
    "            (~df['Notes'].str.contains('sister')) &\n",
    "            (~df['Notes'].str.contains('Fined')) &\n",
    "            (~df['Notes'].str.contains('flu')) &\n",
    "            (~df['Notes'].str.contains('GM')) &\n",
    "            (~df['Notes'].str.contains('flu')) &\n",
    "            (~df['Notes'].str.contains('team')) &\n",
    "            (~df['Notes'].str.contains('canal')) &\n",
    "            (~df['Notes'].str.contains('food')) &\n",
    "            (~df['Notes'].str.contains('virus')) &\n",
    "            (~df['Notes'].str.contains('wife')) &\n",
    "            (~df['Notes'].str.contains('asthma')) &\n",
    "            (~df['Notes'].str.contains('chin')) &\n",
    "            (~df['Notes'].str.contains('headache')) &\n",
    "            (~df['Notes'].str.contains('anemia')) &\n",
    "            (~df['Notes'].str.contains('dizziness')) &\n",
    "            (~df['Notes'].str.contains('cold')) &\n",
    "            (~df['Notes'].str.contains('throat')) &\n",
    "            (~df['Notes'].str.contains('molar')) &\n",
    "            (~df['Notes'].str.contains('dizziness')) &\n",
    "            (~df['Notes'].str.contains('rash')) &\n",
    "            (~df['Notes'].str.contains('stomach ache')) &\n",
    "            (~df['Notes'].str.contains('bronchitis')) &\n",
    "            (~df['Notes'].str.contains('concussion')) &\n",
    "            (~df['Notes'].str.contains('recover')) &\n",
    "            (~df['Notes'].str.contains('mump'))]\n",
    "\n",
    "    # clean notes\n",
    "    df['Notes'] = df['Notes'].apply(clean_notes)\n",
    "    \n",
    "    # stripping blank spaces from player names\n",
    "    df['Player'] = df['Player'].apply(lambda x: x.strip())\n",
    "    \n",
    "    # removing periods from names like C.J.\n",
    "    df['Player'] = df['Player'].apply(lambda x: ''.join(x.split('.')) if re.match(r'\\w\\.\\w\\.', x) else x)\n",
    "    \n",
    "    # removing characters like (a) and (b)\n",
    "    df['Player'] = df['Player'].apply(lambda x: ' '.join(x.split()[:2]) if re.match(r'.+\\(.+\\)', x) else x)\n",
    "    \n",
    "    df[df['Player'] == '(William) Tony Parker']['Player'] = 'Tony Parker'\n",
    "    df = df[df['Player'] != '']\n",
    "\n",
    "    unique_players = gamelog_df['PLAYER_NAME'].unique()\n",
    "    for player in unique_players:\n",
    "        df['Player'] = df['Player'].apply(lambda x: player if player in x else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# preprocess\n",
    "def prep_gamelog(df):\n",
    "\n",
    "    # converting the Date column to datetime objects\n",
    "    df = parse_date(df, 'GAME_DATE')\n",
    "\n",
    "    drop_vars = ['SEASON_ID', 'TEAM_ABBREVIATION', 'TEAM_NAME',\n",
    "                 'WL', 'FG_PCT', 'FG3_PCT', 'FT_PCT',\n",
    "                 'VIDEO_AVAILABLE']\n",
    "    df.drop(drop_vars, axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def start_end_season(keyword, add_year=False):\n",
    "\n",
    "    fns = os.listdir('data/')\n",
    "    cols = json_extract('2013_{}.json'.format(keyword))[0]\n",
    "    if add_year:\n",
    "        cols += ['YEAR']\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    season_range = []\n",
    "    for fn in fns:\n",
    "        if keyword in fn:\n",
    "            cols, vals = json_extract(fn)\n",
    "            df = pd.DataFrame(vals, columns=cols)\n",
    "            season_range.append((datetime.strptime(df['GAME_DATE'].min(), '%Y-%m-%d'),\n",
    "                                 datetime.strptime(df['GAME_DATE'].max(), '%Y-%m-%d')))            \n",
    "    return season_range\n",
    "\n",
    "\n",
    "def create_feat_mat(df, data_window=21):\n",
    "    feat_mat = pd.DataFrame()\n",
    "    player_id = df['PLAYER_ID'].unique().tolist()\n",
    "    for id in player_id:\n",
    "        tmp = df[df['PLAYER_ID'] == id]\n",
    "        roll_mean_df = pd.rolling_mean(tmp, data_window)\n",
    "        feat_mat = feat_mat.append(roll_mean_df)\n",
    "    return feat_mat\n",
    "\n",
    "\n",
    "def pickles_to_pandas(keyword, add_year=False):\n",
    "    \n",
    "    fns = os.listdir('data/')\n",
    "    with open('data/2014_{}_stats.pickle'.format(keyword), 'r') as f:\n",
    "        pkl_f = pickle.load(f)\n",
    "        cols = pkl_f[0]['resultSets'][0]['headers']\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    for fn in fns:\n",
    "        if keyword in fn:\n",
    "            with open('data/{}'.format(fn), 'r') as f:\n",
    "                pkl_f = pickle.load(f)\n",
    "            for item in pkl_f:\n",
    "                tmp_cols = item['resultSets'][0]['headers']\n",
    "                tmp_vals = item['resultSets'][0]['rowSet']\n",
    "                df_tmp = pd.DataFrame(tmp_vals, columns=tmp_cols)\n",
    "                if add_year:\n",
    "                    df_tmp['YEAR'] = int(fn[0:4])\n",
    "                df = df.append(df_tmp)\n",
    "                del df_tmp, tmp_cols, tmp_vals\n",
    "    return df\n",
    "        \n",
    "def shuffle_rows(df):\n",
    "  return df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/peter/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/peter/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/peter/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/peter/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "ss_df = create_df('season_stats', add_year=True)\n",
    "hw_df = create_df('heights_weights', add_year=True)\n",
    "gamelog_df = create_df('gamelog')\n",
    "gamelog_df = prep_gamelog(gamelog_df)\n",
    "injury_df = pd.read_csv('data/injuries.csv')\n",
    "injury_df = prep_injury(injury_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamelog = gamelog_df\n",
    "injury = injury_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/anaconda2/lib/python2.7/site-packages/pandas/core/frame.py:2754: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "start_data = datetime.strptime('10-29-2013', '%m-%d-%Y')\n",
    "gamelog = gamelog[gamelog['GAME_DATE'] >= start_data]\n",
    "injury = injury[injury['Date'] >= start_data]\n",
    "hw_df = hw_df[hw_df['YEAR'] >= 2013]\n",
    "injury.rename(columns={'Player':'Player_Injury',\n",
    "                       'Date': 'Date_Injury'\n",
    "                      },\n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pace_tracking(keep_cols, keyword):\n",
    "    df = pickles_to_pandas(keyword, add_year=True)\n",
    "    df.drop(df.columns - keep_cols, axis=1, inplace=True)\n",
    "    df.rename(columns={'GAME_ID': 'GAME_ID_{}'.format(keyword.upper()),\n",
    "                     'PLAYER_NAME': 'PLAYER_NAME_{}'.format(keyword.upper()),\n",
    "                     'PLAYER_ID': 'PLAYER_ID_{}'.format(keyword.upper()),\n",
    "                     'YEAR': 'YEAR_{}'.format(keyword.upper())},\n",
    "              inplace=True) \n",
    "    return df\n",
    "    \n",
    "pace_keep_cols = ['GAME_ID', 'PACE', 'PLAYER_ID', 'PLAYER_NAME', 'YEAR']\n",
    "tracking_keep_cols = ['GAME_ID', 'SPD', 'DIST', 'PLAYER_ID', 'PLAYER_NAME', 'YEAR']\n",
    "    \n",
    "tracking = pace_tracking(tracking_keep_cols, 'tracking')\n",
    "pace = pace_tracking(pace_keep_cols, 'pace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pace = pickles_to_pandas('pace', add_year=True)\n",
    "# pace_keep_cols = ['GAME_ID', 'PACE', 'PLAYER_ID', 'PLAYER_NAME', 'YEAR']\n",
    "# pace_drop_cols = pace.columns - pace_keep_cols\n",
    "# pace.drop(pace_drop_cols, axis=1, inplace=True)\n",
    "# pace.rename(columns={'GAME_ID':'GAME_ID_PACE',\n",
    "#                      'PLAYER_NAME': 'PLAYER_NAME_PACE',\n",
    "#                      'PLAYER_ID': 'PLAYER_ID_PACE',\n",
    "#                      'YEAR': 'YEAR_PACE'},\n",
    "#             inplace=True)\n",
    "\n",
    "# tracking = pickles_to_pandas('tracking', add_year=True)\n",
    "# tracking_keep_cols = ['GAME_ID', 'SPD', 'DIST', 'PLAYER_ID', 'PLAYER_NAME', 'YEAR']\n",
    "# tracking_drop_cols = tracking.columns - tracking_keep_cols\n",
    "# tracking.drop(tracking_drop_cols, axis=1, inplace=True)\n",
    "# tracking.rename(columns={'GAME_ID':'GAME_ID_TRACKING',\n",
    "#                      'PLAYER_NAME': 'PLAYER_NAME_TRACKING',\n",
    "#                      'PLAYER_ID': 'PLAYER_ID_TRACKING',\n",
    "#                      'YEAR': 'YEAR_TRACKING'},\n",
    "#             inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GAME_ID_PACE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-576370226d4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m gamelog = gamelog.merge(pace, left_on=['GAME_ID', 'PLAYER_ID'],\n\u001b[1;32m----> 2\u001b[1;33m                              right_on=['GAME_ID_PACE', 'PLAYER_ID_PACE'])\n\u001b[0m\u001b[0;32m      3\u001b[0m gamelog = gamelog.merge(tracking, left_on=['GAME_ID', 'PLAYER_ID'],\n\u001b[0;32m      4\u001b[0m                                 right_on=['GAME_ID_TRACKING', 'PLAYER_ID_TRACKING'])\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[0;32m   4435\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4436\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4437\u001b[1;33m                      copy=copy, indicator=indicator)\n\u001b[0m\u001b[0;32m   4438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4439\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[0;32m     36\u001b[0m                          \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                          copy=copy, indicator=indicator)\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[0;32m    208\u001b[0m         (self.left_join_keys,\n\u001b[0;32m    209\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m                         \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m                             \u001b[1;31m# avoid key upcast in corner case (length-0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1995\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1997\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1999\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2002\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2003\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2004\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3290\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3291\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   1945\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1946\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1947\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'GAME_ID_PACE'"
     ]
    }
   ],
   "source": [
    "gamelog = gamelog.merge(pace, left_on=['GAME_ID', 'PLAYER_ID'],\n",
    "                             right_on=['GAME_ID_PACE', 'PLAYER_ID_PACE'])\n",
    "gamelog = gamelog.merge(tracking, left_on=['GAME_ID', 'PLAYER_ID'],\n",
    "                                right_on=['GAME_ID_TRACKING', 'PLAYER_ID_TRACKING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city_abbrv = {'ATL': 'Atlanta',\n",
    "              'BOS': 'Boston',\n",
    "              'CLE': 'Cleveland',\n",
    "              'GSW': 'Oakland',\n",
    "              'OKC': 'Oklahoma+City',\n",
    "              'SAS': 'San+Antonio',\n",
    "              'POR': 'Portland',\n",
    "              'MIA': 'Miami',\n",
    "              'IND': 'Indiana',\n",
    "              'TOR': 'Toronoto',\n",
    "              'CHI': 'Chicago',\n",
    "              'BKN': 'Brooklyn',\n",
    "              'CHA': 'Charlotte',\n",
    "              'NYK': 'New+York',\n",
    "              'DET': 'Detroit',\n",
    "              'PHI': 'Philadelphia',\n",
    "              'ORL': 'Orlando',\n",
    "              'MIL': 'Milwaukee',\n",
    "              'WAS': 'Washington+DC',\n",
    "              'DEN': 'Denver',\n",
    "              'DAL': 'Dallas',\n",
    "              'MIN': 'Minnesota',\n",
    "              'LAC': 'Los+Angeles',\n",
    "              'HOU': 'Houston',\n",
    "              'LAL': 'Los+Angeles',\n",
    "              'MEM': 'Memphis',\n",
    "              'PHX': 'Phoenix',\n",
    "              'NOP': 'New+Orleans',\n",
    "              'UTA': 'Utah',\n",
    "              'SAC': 'Sacramento'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def game_loc(x):\n",
    "    if 'vs.' in x:\n",
    "        return city_abbrv[re.split(r' vs. ', x)[0]]\n",
    "    elif '@' in x:\n",
    "        return city_abbrv[re.split(r' @ ', x)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamelog['GAME_LOCATION'] = gamelog['MATCHUP'].apply(lambda x: game_loc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating dataframe of everyday in a season\n",
    "season_dt_range = start_end_season('gamelog')\n",
    "\n",
    "seasons = pd.DataFrame(columns=['Date'])\n",
    "for range in season_dt_range:\n",
    "    tmp = pd.DataFrame(pd.date_range(range[0], range[1], freq='D'), columns=['Date'])\n",
    "    seasons = seasons.append(tmp)\n",
    "\n",
    "seasons = seasons[seasons['Date'] > start_data]\n",
    "seasons.sort_values('Date', inplace=True)\n",
    "seasons.rename(columns={'Date': 'Season Dates'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gamelog_injury = gamelog.merge(injury, left_on=['GAME_DATE', 'PLAYER_NAME'],\n",
    "                                       right_on=['Date_Injury', 'Player_Injury'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropping conflicted rows when the injury data indicated a player sat out when he, in fact, did play\n",
    "conflict_idx = gamelog_injury.index[gamelog_injury[(gamelog_injury['GAME_DATE'].notnull()) &\n",
    "                                                   (gamelog_injury['Date_Injury'].notnull())].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamelog_injury.drop(conflict_idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combining the non-nan GAME_DATE and non-nan Date values into one column\n",
    "GAME_DATE = gamelog_injury['GAME_DATE'].dropna()\n",
    "date = gamelog_injury['Date_Injury'].dropna()\n",
    "combined_date = pd.concat([GAME_DATE, date])\n",
    "\n",
    "# combining the non-nan PLAYER_NAME and non-nan Player values into one column\n",
    "PLAYER_NAME = gamelog_injury['PLAYER_NAME'].dropna()\n",
    "Player = gamelog_injury['Player_Injury'].dropna()\n",
    "combined_player = pd.concat([PLAYER_NAME, Player])\n",
    "\n",
    "gamelog_injury['DATE'] = combined_date\n",
    "gamelog_injury['PLAYER'] = combined_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gamelog_injury.sort_values('DATE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/city_distances.pickle', 'r') as f:\n",
    "    city_distances = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "players = gamelog_injury['PLAYER'].unique().tolist()\n",
    "\n",
    "# creating an injury flag column\n",
    "# a player is marked as injured if an injury occurred in any of the next 3 games\n",
    "merged = pd.DataFrame()\n",
    "for player in players:\n",
    "    tmp = gamelog_injury[gamelog_injury['PLAYER'] == player]\n",
    "    tmp['INJURED'] = 0\n",
    "    tmp['MILES_TRAVELED'] = 0\n",
    "    for i in xrange(len(tmp) - 1):\n",
    "        if tmp['Notes'].iloc[i+1: i+4].notnull().sum() > 0:\n",
    "            tmp['INJURED'].iloc[i] = 1\n",
    "    \n",
    "        city1 = tmp['GAME_LOCATION'].iloc[i]\n",
    "        city2 = tmp['GAME_LOCATION'].iloc[i+1]\n",
    "        if city1 == city2:\n",
    "            pass\n",
    "        if (city1, city2) in set(city_distances.keys()):\n",
    "            tmp['MILES_TRAVELED'].iloc[i+1] = city_distances[(city1, city2)]\n",
    "        elif (city2, city1) in set(city_distances.keys()):\n",
    "            tmp['MILES_TRAVELED'].iloc[i+1] = city_distances[(city2, city1)]\n",
    "    merged = merged.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# zero mins played indicate the player played less than one minute.\n",
    "# Treating those players as not playing\n",
    "exclude_cols = ['PLAYER', 'DATE', 'INJURED', 'PLAYER_ID', 'NOTES']\n",
    "merged.ix[merged['MIN'] <= 1.0, merged.columns - exclude_cols] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# counting the number of games played in the aggregation window\n",
    "merged['GAMES_PLAYED'] = merged['MIN'].notnull() * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a column to count back to back games\n",
    "merged[\"BACK_TO_BACKS\"] = 0\n",
    "for i in xrange(len(merged)-1):\n",
    "    if merged['DATE'].iloc[i] + pd.DateOffset(days=1) == merged['DATE'].iloc[i+1]:\n",
    "        merged[\"BACK_TO_BACKS\"].iloc[i+1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function that aggregates the stats within a window of specified days\n",
    "def agg_stats(df, window=14):\n",
    "    columns = df.columns.tolist()\n",
    "    cat_dict = defaultdict(list)\n",
    "    for i in xrange(0, len(df)):\n",
    "        for col in columns:\n",
    "            #create a dictionary to store the stats for each category\n",
    "            cat_dict[col].append(np.nanmean(df[col].iloc[i-window: i]))\n",
    "        # create a new column that records the number of games played within the window\n",
    "        cat_dict['GAMES_PLAYED_IN_WINDOW'].append(np.nansum(df['GAMES_PLAYED'].iloc[i-window: i]))\n",
    "        cat_dict['B2B_PLAYED_IN_WINDOW'].append(np.nansum(df[\"BACK_TO_BACKS\"].iloc[i-window: i]))\n",
    "        cat_dict['TOTAL_MILES_TRAVELED'].append(np.nansum(df[\"MILES_TRAVELED\"].iloc[i-window: i]))\n",
    "    return pd.DataFrame(cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rolling_window = pd.DataFrame()\n",
    "feat_mat = pd.DataFrame()\n",
    "j = 0\n",
    "for player in players:\n",
    "#     print player, j/float(len(players))\n",
    "    player_df = merged[merged['PLAYER'] == player]\n",
    "    # maps a player's gamelog to all of the calender dates in a regular season\n",
    "    player_season = seasons.merge(player_df, left_on='Season Dates', right_on='DATE', how='left')\n",
    "    # remove the columns that will not be aggregated\n",
    "    cols_split = player_season[['Season Dates', 'PLAYER', 'INJURED', 'Notes']]\n",
    "    # dropping columns that cannot be aggregated\n",
    "    drop_player_season = ['PLAYER_NAME', 'GAME_DATE', 'YEAR_x', 'YEAR_y', 'INJURED',\n",
    "                          'MONTH_x', 'MONTH_y', 'DAY_x', 'Date_Injury', 'Player_Injury', 'Notes',\n",
    "                          'DATE', 'DAY_y', 'PLAYER', 'PLAYER_NAME_PACE', 'Season Dates',\n",
    "                          'PLAYER_NAME_TRACKING', 'GAME_ID', 'YEAR_TRACKING', 'YEAR_PACE',\n",
    "                          'GAME_ID_TRACKING', 'GAME_ID_PACE', 'MATCHUP', 'GAME_LOCATION']\n",
    "    player_season.drop(drop_player_season, axis=1, inplace=True)\n",
    "    rolling_window = agg_stats(player_season, window=21)\n",
    "    # add the aggregated stats and the earlier removed columns to the feature matrix\n",
    "    feat_mat = feat_mat.append(pd.concat([rolling_window, cols_split], axis=1))\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop all nan's from the feature matrix\n",
    "# the nan's represent games in which the player did not play in\n",
    "feat_mat.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert the weights in the height/weight dataframe to floats\n",
    "hw_df['PLAYER_WEIGHT'] = hw_df['PLAYER_WEIGHT'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# defines the start of the season for each row\n",
    "def define_season(x):    \n",
    "    for season in season_dt_range:\n",
    "        if (x >= season[0]) & (x <= season[1]):\n",
    "            return season[0]\n",
    "\n",
    "feat_mat['START_SEASON'] = feat_mat['Season Dates'].apply(define_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# custom apply function to match stats from other dataframes to the feature matrix\n",
    "# appends the height, weight, and age based on the player and the year\n",
    "def add_bi_comp_feat(df, player, start_season, feat):\n",
    "    if df[(df['PLAYER_NAME'] == player) &\n",
    "              (df['YEAR'] == start_season.year)][feat].empty:\n",
    "        return None\n",
    "    return df[(df['PLAYER_NAME'] == player) &\n",
    "              (df['YEAR'] == start_season.year)][feat].values[0]\n",
    "\n",
    "feat_mat['HEIGHT'] = 0\n",
    "feat_mat['HEIGHT'] = feat_mat.apply(lambda x: add_bi_comp_feat(hw_df,\n",
    "                                                               x['PLAYER'],\n",
    "                                                               x['START_SEASON'],\n",
    "                                                               'PLAYER_HEIGHT_INCHES'),\n",
    "                                   axis=1)\n",
    "\n",
    "feat_mat['WEIGHT'] = 0\n",
    "feat_mat['WEIGHT'] = feat_mat.apply(lambda x: add_bi_comp_feat(hw_df,\n",
    "                                                               x['PLAYER'],\n",
    "                                                               x['START_SEASON'],\n",
    "                                                               'PLAYER_WEIGHT'),\n",
    "                                    axis=1)\n",
    "\n",
    "feat_mat['AGE'] = 0\n",
    "feat_mat['AGE'] = feat_mat.apply(lambda x: add_bi_comp_feat(ss_df,\n",
    "                                                            x['PLAYER'],\n",
    "                                                            x['START_SEASON'],\n",
    "                                                            'AGE'),\n",
    "                                 axis=1)\n",
    "\n",
    "feat_mat['AGE'] = 0\n",
    "feat_mat['AGE'] = feat_mat.apply(lambda x: add_bi_comp_feat(ss_df,\n",
    "                                                            x['PLAYER'],\n",
    "                                                            x['START_SEASON'],\n",
    "                                                            'AGE'),\n",
    "                                 axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FITTING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xy = feat_mat.drop(['PLAYER', 'PLAYER_ID', 'FG3M', 'Season Dates',\n",
    "                    'FGM', 'FTM', 'BLK', 'PLUS_MINUS', 'START_SEASON',\n",
    "                    'PTS', 'REB', 'GAMES_PLAYED', 'PLAYER_ID_PACE',\n",
    "                    'PLAYER_ID_TRACKING', 'BACK_TO_BACKS', 'PACE', 'MIN',\n",
    "                    'GAMES_PLAYED_IN_WINDOW', 'B2B_PLAYED_IN_WINDOW',\n",
    "                    'HEIGHT', 'FGA', 'MILES_TRAVELED', 'Notes'], axis=1)\n",
    "Xy.dropna(inplace=True)\n",
    "Xy.reset_index(inplace=True, drop=True)\n",
    "Xy = Xy[Xy['SPD'] != 0.0]\n",
    "Xy.rename(columns={'TOTAL_MILES_TRAVELED': 'MILES TRAVELED',\n",
    "                   'SPD': 'SPEED',\n",
    "                   'DIST': 'DISTANCE',\n",
    "                   'AST': 'ASSISTS',\n",
    "                   'DREB': 'DEFENSIVE REBOUNDS',\n",
    "                   'OREB': 'OFFENSIVE REBOUNDS',\n",
    "                   'PF': 'PERSONAL FOULS',\n",
    "                   'STL': 'STEALS',\n",
    "                   'TOV': 'TURNOVERS',\n",
    "                   'FTA': 'FREETHROWS ATTEMPTED',\n",
    "                   'FG3A': '3-POINTERS ATTEMPTED'},\n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = Xy['INJURED']\n",
    "X = Xy.drop('INJURED', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=.3)\n",
    "X_subtrain, X_subtest, y_subtrain, y_subtest = train_test_split(X_train, y_train, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegressionCV(cv=3).fit(X_subtrain, y_subtrain)\n",
    "logreg_prob = logreg.predict_proba(X_holdout)[:, 1]\n",
    "logreg_pred = logreg.predict(x_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=250,\n",
    "                             class_weight='balanced', \n",
    "                             max_features='log2',\n",
    "                             n_jobs=-1,\n",
    "                             oob_score=True).fit(X_subtrain, y_subtrain)\n",
    "rfc_prob = rfc.predict_proba(X_holdout)[:, 1]\n",
    "rfc_pred = rfc.predict(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rfc_param_grid = {'n_estimators': [50, 100, 150, 200, 250],\n",
    "#               'min_samples_leaf': [1, 10, 20, 50],\n",
    "#               'max_features': ['sqrt', 'log2']}\n",
    "# rfc_gs = GridSearchCV(rfc, param_grid=rfc_param_grid, scoring='roc_auc', cv=5, n_jobs=-1).fit(X_subtrain, y_subtrain)\n",
    "# \n",
    "# rfc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(learning_rate=.2,\n",
    "                                 n_estimators=250,\n",
    "                                 max_depth=10,\n",
    "                                 max_features='sqrt').fit(X_subtrain, y_subtrain)\n",
    "gbc_prob = gbc.predict_proba(X_holdout)[:, 1]\n",
    "gbc_pred = gbc.predict(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gbc_param_grid = {'learning_rate': [.05, .1, .2, .5],\n",
    "#                   'n_estimators': [50, 100, 150, 200],\n",
    "#                   'max_depth': [1, 3, 6, 10],\n",
    "#                   'max_features': ['auto', 'sqrt']}\n",
    "# gbc_gs = GridSearchCV(gbc, param_grid=gbc_param_grid, scoring='roc_auc', cv=5, n_jobs=-1).fit(X_subtrain, y_subtrain)\n",
    "\n",
    "# gbc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for probs in [logreg_prob, rfc_prob, gbc_prob]:\n",
    "    fpr, tpr, thres1 = roc_curve(y_true, probs)\n",
    "    random_prob = np.random.random(y_true.shape[0])\n",
    "    random_precision, random_recall, thres2 = precision_recall_curve(y_true, random_prob)\n",
    "    precision, recall, thres2 = precision_recall_curve(y_true, probs)\n",
    "    with plt.style.context('fivethirtyeight'):\n",
    "        fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
    "        ax2.plot(recall, precision)\n",
    "        ax2.fill_between(recall, 0, precision, alpha=.2)\n",
    "        ax2.plot(random_recall, random_precision, alpha=.4)\n",
    "        ax2.fill_between(random_recall, 0, random_precision, alpha=.2, color='r')\n",
    "        ax2.set_title('PRECISION-RECALL CURVE')\n",
    "        ax2.set_xlabel('RECALL')\n",
    "        ax2.set_ylabel('PRECISION')\n",
    "        ax2.text(1.1, 1, 'P-R AUC: {:.3f}'.format(auc(recall, precision)))\n",
    "        fig2.savefig('images/rfc_pr_curve.png')\n",
    "ax2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def roc_pr(y_true, probs):\n",
    "    fpr, tpr, thres1 = roc_curve(y_true, probs)\n",
    "    random_prob = np.random.random(y_true.shape[0])\n",
    "    random_precision, random_recall, thres2 = precision_recall_curve(y_true, random_prob)\n",
    "    precision, recall, thres2 = precision_recall_curve(y_true, probs)\n",
    "    with plt.style.context('fivethirtyeight'):\n",
    "        fig1, ax1 = plt.subplots(figsize=(8, 8))\n",
    "        ax1.plot(fpr, tpr)\n",
    "        ax1.fill_between(fpr, 0, tpr, alpha=.2)\n",
    "        ax1.plot(np.linspace(0, 1), np.linspace(0, 1), alpha=.4, color='r')\n",
    "        ax1.fill_between(np.linspace(0, 1), 0, np.linspace(0, 1), alpha=.2)\n",
    "        ax1.set_title('ROC CURVE')\n",
    "        ax1.set_xlabel('FALSE POSITIVE RATE')\n",
    "        ax1.set_ylabel('TRUE POSITIVE RATE')\n",
    "        ax1.text(1.1, 1, 'ROC AUC: {:.3f}'.format(roc_auc_score(y_true, probs)))\n",
    "        fig1.savefig('images/rfc_roc_curve.png')\n",
    "\n",
    "        fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
    "        ax2.plot(recall, precision)\n",
    "        ax2.fill_between(recall, 0, precision, alpha=.2)\n",
    "        ax2.plot(random_recall, random_precision, alpha=.4)\n",
    "        ax2.fill_between(random_recall, 0, random_precision, alpha=.2, color='r')\n",
    "        ax2.set_title('PRECISION-RECALL CURVE')\n",
    "        ax2.set_xlabel('RECALL')\n",
    "        ax2.set_ylabel('PRECISION')\n",
    "        ax2.text(1.1, 1, 'P-R AUC: {:.3f}'.format(auc(recall, precision)))\n",
    "        fig2.savefig('images/rfc_pr_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_pr(y_holdout, rfc_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(rfc, X_train, y_train, cv=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CROSS VAL ROC-AUC SCORES:\n",
    "3 WEEKS, DROPPED ['PLAYER', 'PLAYER_ID', 'FG3M', 'Season Dates',\n",
    "                    'FGM', 'FTM', 'BLK', 'PLUS_MINUS', 'START_SEASON',\n",
    "                    'PTS', 'REB', 'GAMES_PLAYED', 'PLAYER_ID_PACE',\n",
    "                    'PLAYER_ID_TRACKING', 'BACK_TO_BACKS', 'SPD', 'DIST',\n",
    "                    'GAMES_PLAYED_IN_WINDOW', 'B2B_PLAYED_IN_WINDOW',\n",
    "                    'HEIGHT', 'FGA']\n",
    "    array([ 0.87532727,  0.87210658,  0.86860892])\n",
    "3 WEEKS, DROPPED ['PLAYER', 'PLAYER_ID', 'FG3M', 'Season Dates',\n",
    "                    'FGM', 'FTM', 'BLK', 'PLUS_MINUS', 'START_SEASON',\n",
    "                    'PTS', 'REB', 'GAMES_PLAYED', 'PLAYER_ID_PACE',\n",
    "                    'PLAYER_ID_TRACKING', 'BACK_TO_BACKS', 'SPD', 'MIN',\n",
    "                    'GAMES_PLAYED_IN_WINDOW', 'B2B_PLAYED_IN_WINDOW',\n",
    "                    'HEIGHT', 'FGA']\n",
    "    array([ 0.86971471,  0.86214867,  0.87307729])\n",
    "3 WEEKS, DROPPED ['PLAYER', 'PLAYER_ID', 'FG3M', 'Season Dates',\n",
    "                    'FGM', 'FTM', 'BLK', 'PLUS_MINUS', 'START_SEASON',\n",
    "                    'PTS', 'REB', 'GAMES_PLAYED', 'PLAYER_ID_PACE',\n",
    "                    'PLAYER_ID_TRACKING', 'BACK_TO_BACKS', 'SPD',\n",
    "                    'GAMES_PLAYED_IN_WINDOW', 'B2B_PLAYED_IN_WINDOW',\n",
    "                    'HEIGHT', 'FGA']\n",
    "    array([ 0.865748  ,  0.85877329,  0.87224933])\n",
    "3 WEEKS, DROPPED ['PLAYER', 'PLAYER_ID', 'FG3M', 'Season Dates',\n",
    "                    'FGM', 'FTM', 'BLK', 'PLUS_MINUS', 'START_SEASON',\n",
    "                    'PTS', 'REB', 'GAMES_PLAYED', 'PLAYER_ID_PACE',\n",
    "                    'PLAYER_ID_TRACKING', 'BACK_TO_BACKS', 'PACE', 'DIST',\n",
    "                    'GAMES_PLAYED_IN_WINDOW', 'B2B_PLAYED_IN_WINDOW',\n",
    "                    'HEIGHT', 'FGA']\n",
    "         REMOVED ENTRIES WITH 0 SPEED\n",
    "     array([ 0.86799017,  0.86427741,  0.87295606])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = X.columns\n",
    "importances = rfc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfc.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "\n",
    "# for f in xrange(X.shape[1]):\n",
    "#     print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "    \n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.suptitle('FEATURE IMPORTANCES', fontsize=20, y=1.1)\n",
    "    plt.bar(np.arange(X.shape[1]), importances[indices],\n",
    "           color=\"r\", alpha=.8, yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(np.arange(X.shape[1]), features[indices], rotation='vertical')\n",
    "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "    plt.xlabel('FEATURES', fontsize=14)\n",
    "    plt.ylabel('IMPORTANCES', fontsize=14)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.savefig('images/feature_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
